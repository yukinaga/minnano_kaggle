{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_hyperparameter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOwCB/n9gXm6tYi9djcclOU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yukinaga/minnano_kaggle/blob/main/section_3/02_hyperparameter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ハイパーパラメータの調整\n",
        "精度向上のために、ハイパーパラメータを調整します。 "
      ],
      "metadata": {
        "id": "E-QmT8-Qhgt9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optunaのインストール\n",
        "ハイパーパラメータの最適化に使用するライブラリ、Optunaをインストールします。"
      ],
      "metadata": {
        "id": "4GOZZBYIhsLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "gP5NcAIgz-3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データの準備\n",
        "必要なライブラリの導入、データの読み込みと加工を行います。"
      ],
      "metadata": {
        "id": "sW2dwjT2kYqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "import lightgbm as lgb\n",
        "import optuna\n",
        "\n",
        "train_data = pd.read_csv(\"train.csv\")  # 訓練データ\n",
        "test_data = pd.read_csv(\"test.csv\") # テストデータ\n",
        "\n",
        "test_id = test_data[\"PassengerId\"]  # 結果の提出時に使用\n",
        "\n",
        "data = pd.concat([train_data, test_data], sort=False)  # テストデータ、訓練データを結合\n",
        "\n",
        "# カテゴリデータの変換\n",
        "data[\"Sex\"].replace([\"male\", \"female\"], [0, 1], inplace=True)\n",
        "data[\"Embarked\"].fillna((\"S\"), inplace=True)\n",
        "data[\"Embarked\"] = data[\"Embarked\"].map({\"S\": 0, \"C\": 1, \"Q\": 2})\n",
        "\n",
        "# 欠損値を埋める\n",
        "data[\"Fare\"].fillna(data[\"Fare\"].mean(), inplace=True)\n",
        "data[\"Age\"].fillna(data[\"Age\"].mean(), inplace=True)\n",
        "\n",
        "# 新しい特徴量の作成\n",
        "data[\"Family\"] = data[\"Parch\"] + data[\"SibSp\"]\n",
        "\n",
        "# 不要な特徴量の削除\n",
        "data.drop([\"Name\", \"PassengerId\", \"SibSp\", \"Parch\", \"Ticket\", \"Cabin\"],\n",
        "          axis=1, inplace=True)\n",
        "\n",
        "# 入力と正解の作成\n",
        "train_data = data[:len(train_data)]\n",
        "test_data = data[len(train_data):]\n",
        "t = train_data[\"Survived\"]  # 正解\n",
        "x_train = train_data.drop(\"Survived\", axis=1)  # 訓練時の入力\n",
        "x_test = test_data.drop(\"Survived\", axis=1)  # テスト時の入力\n",
        "\n",
        "x_train.head()"
      ],
      "metadata": {
        "id": "Jwulz4eYsxZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## データの分割\n",
        "訓練用データを訓練用と検証用に分割します。"
      ],
      "metadata": {
        "id": "UvCs34hNk8Ue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_valid, t_train, t_valid = train_test_split(x_train, t, test_size=0.3, stratify=t)"
      ],
      "metadata": {
        "id": "sVUg5z780_NI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ハイパーパラメータの最適化\n",
        "ハイパーパラメータ最適化のための関数を用意します。  \n",
        "最適化には、Optunaというライブラリを使用します。  \n",
        "https://github.com/optuna/optuna  \n",
        "  \n",
        "また、機械学習のアルゴリズムには決定木をベースにした「LightGBM」を使います。  \n",
        "LightGBMは「勾配ブースティング」の一種で使い勝手が良く、多くのKaggle上位者に使用された実績があります。  \n",
        "大量の決定木を使用し、ある決定木の予測結果から誤差の大きなデータをうまく予測できるように次の決定木を作成します。  \n",
        "https://lightgbm.readthedocs.io/en/latest/\n"
      ],
      "metadata": {
        "id": "Zhxmw8thl7fY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_features = [\"Embarked\", \"Pclass\", \"Sex\"]\n",
        "\n",
        "def objective(trial):\n",
        "    # ハイパーパラメータの探索範囲\n",
        "    params = {\n",
        "        \"objective\": \"binary\",  # 二値分類\n",
        "        \"max_bin\": trial.suggest_int(\"max_bin\", 200, 500),  # 特徴量の最大分割数\n",
        "        \"learning_rate\": 0.05,  # 学習率\n",
        "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 16, 128)  # 分岐の末端の最大数\n",
        "    }\n",
        "\n",
        "    # データセットの作成\n",
        "    lgb_train = lgb.Dataset(x_train, t_train, categorical_feature=categorical_features)\n",
        "    lgb_val = lgb.Dataset(x_valid, t_valid, reference=lgb_train, categorical_feature=categorical_features)\n",
        "\n",
        "    # モデルの訓練\n",
        "    model = lgb.train(params, lgb_train, valid_sets=[lgb_train, lgb_val],\n",
        "                      verbose_eval=20,  # 学習過程の表示間隔\n",
        "                      num_boost_round=500,  # 学習回数の最大値\n",
        "                      early_stopping_rounds=10)  # 連続して10回性能が向上しなければ終了\n",
        "\n",
        "    y_valid = model.predict(x_valid, num_iteration=model.best_iteration)  # 訓練済みのモデルを使用\n",
        "    score = log_loss(t_valid, y_valid)  # 二値の交差エントロピー誤差\n",
        "    return score"
      ],
      "metadata": {
        "id": "UqYeGOLSyD1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optunaを使い、ハイパーパラメータを最適化します。\n"
      ],
      "metadata": {
        "id": "tfYx-oIBrGAK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(sampler=optuna.samplers.RandomSampler())\n",
        "study.optimize(objective, n_trials=30)"
      ],
      "metadata": {
        "id": "zPNB4Ve9yizH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ベストなハイパーパラメータを表示します。"
      ],
      "metadata": {
        "id": "h3re-9FVulHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(study.best_params)"
      ],
      "metadata": {
        "id": "djKFXXxxzu3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ベストなハイパーパラメータを使って予測を行います。"
      ],
      "metadata": {
        "id": "W9RY7xAKuxKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ベストなハイパーパラメータの設定\n",
        "params = {\n",
        "    \"objective\": \"binary\",  # 二値分類\n",
        "    \"max_bin\": study.best_params[\"max_bin\"],  # 特徴量の最大分割数\n",
        "    \"learning_rate\": 0.05,  # 学習率\n",
        "    \"num_leaves\": study.best_params[\"num_leaves\"]  # 分岐の末端の最大数\n",
        "}\n",
        "\n",
        "# データセットの作成\n",
        "lgb_train = lgb.Dataset(x_train, t_train, categorical_feature=categorical_features)\n",
        "lgb_val = lgb.Dataset(x_valid, t_valid, reference=lgb_train, categorical_feature=categorical_features)\n",
        "\n",
        "# モデルの訓練\n",
        "model = lgb.train(params, lgb_train, valid_sets=[lgb_train, lgb_val],\n",
        "                    verbose_eval=20,  # 学習過程の表示間隔\n",
        "                    num_boost_round=500,  # 学習回数の最大値\n",
        "                    early_stopping_rounds=10)  # 連続して10回性能が向上しなければ終了\n",
        "\n",
        "y_test = model.predict(x_test, num_iteration=model.best_iteration)  # 訓練済みのモデルを使用"
      ],
      "metadata": {
        "id": "irCJw2BMzybC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 提出用のデータ\n",
        "提出量データの形式を整え、CSVファイルに保存します。"
      ],
      "metadata": {
        "id": "juDDBtxyw0XU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 結果を0か1に\n",
        "y_test = (y_test > 0.5).astype(int)\n",
        "\n",
        "# 形式を整える\n",
        "survived_test = pd.Series(y_test, name=\"Survived\")\n",
        "subm_data = pd.concat([test_id, survived_test], axis=1)\n",
        "\n",
        "# 提出用のcsvファイルを保存\n",
        "subm_data.to_csv(\"submission_titanic_hp.csv\", index=False)\n",
        "\n",
        "subm_data"
      ],
      "metadata": {
        "id": "LObtFCB9z5OL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}